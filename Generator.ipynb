{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"pred.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"tmR1ur1W9OSR","colab_type":"code","outputId":"a7a1fa59-4b63-4e90-9339-d288e274752a","executionInfo":{"status":"ok","timestamp":1576963984595,"user_tz":-180,"elapsed":28026,"user":{"displayName":"Hakan Sivük","photoUrl":"","userId":"17552002654718297783"}},"colab":{"base_uri":"https://localhost:8080/","height":156}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')\n","\n","!ls /content/gdrive/My\\ Drive/program"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/gdrive\n","1912anim   animLastChance  MIDI-30  MIDI-62  pred.ipynb  songs\n","animLarge  lastAnim\t   MIDI-56  notes    README.txt  Untitled0.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_CWoC-tB9STW","colab_type":"code","outputId":"321edcf6-1806-466c-ca59-b240ca4115ca","executionInfo":{"status":"ok","timestamp":1576965120023,"user_tz":-180,"elapsed":47665,"user":{"displayName":"Hakan Sivük","photoUrl":"","userId":"17552002654718297783"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["import os\n","import argparse\n","import pickle\n","import numpy\n","from music21 import instrument, note, stream, chord, duration\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.layers import Activation\n","from keras.layers import Bidirectional\n","from keras import backend as K\n","from keras.models import load_model\n","\n","TIMESTEP = 0.25\n","SEQUENCE_LEN = int(8 / TIMESTEP)\n","\n","mainPath = \"/content/gdrive/My Drive/program/\"\n","def main():\n","    weights = \"animLastChance/animLastChance-weights-improvement-04-0.0100-bigger.hdf5\"\n","    notes = \"notes/animLastChance\"\n","    g = Generator(mainPath + weights, mainPath + notes)\n","    g.generate()\n","    #model = g.show()\n","    #return model\n","\n","\n","def create_network(network_input, n_vocab):\n","    print(\"Input shape \", network_input.shape)\n","    print(\"Output shape \", n_vocab)\n","    \"\"\" create the structure of the neural network \"\"\"\n","    model = Sequential()\n","    model.add(\n","        Bidirectional(\n","            LSTM(512, return_sequences=True),\n","            input_shape=(network_input.shape[1], network_input.shape[2]),\n","        )\n","    )\n","    model.add(Dropout(0.3))\n","    model.add(Bidirectional(LSTM(512)))\n","    model.add(Dense(n_vocab))\n","    model.add(Activation(\"softmax\"))\n","    model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")\n","\n","    return model\n","\n","class Generator:\n","    def __init__(self, weights, notes):\n","        self.weights = weights\n","        self.notes_file = notes\n","\n","    def show(self):\n","        model = load_model(self.weights)\n","        return model\n","\n","    def generate(self):\n","        \"\"\" Generate a piano midi file \"\"\"\n","        # load the notes used to train the model\n","        with open(self.notes_file, \"rb\") as filepath:\n","            notes = pickle.load(filepath)\n","\n","        # Get all pitch names\n","        pitchnames = sorted(set(item for item in notes))\n","        # Get all pitch names\n","        n_vocab = len(set(notes))\n","        network_input, normalized_input = self.prepare_sequences(\n","            notes, pitchnames, n_vocab\n","        )\n","\n","        #model = create_network(normalized_input, n_vocab)\n","        model = load_model(self.weights)\n","        model.summary()\n","        prediction_output = self.generate_notes(\n","            model, network_input, pitchnames, n_vocab\n","        )\n","        self.create_midi(prediction_output)\n","\n","    def prepare_sequences(self, notes, pitchnames, n_vocab):\n","        \"\"\" Prepare the sequences used by the Neural Network \"\"\"\n","        # map between notes and integers and back\n","        note_to_int = dict((note, number + 1) for number, note in enumerate(pitchnames))\n","        note_to_int[\"NULL\"] = 0\n","\n","        network_input = []\n","        output = []\n","        for i in range(0, len(notes) - SEQUENCE_LEN, 1):\n","            sequence_in = notes[i : i + SEQUENCE_LEN]\n","            sequence_out = notes[i + SEQUENCE_LEN]\n","            network_input.append([note_to_int[char] for char in sequence_in])\n","            output.append(note_to_int[sequence_out])\n","\n","        n_patterns = len(network_input)\n","\n","        # reshape the input into a format compatible with LSTM layers\n","        normalized_input = numpy.reshape(network_input, (n_patterns, SEQUENCE_LEN, 1))\n","        # normalize input\n","        normalized_input = normalized_input / float(n_vocab)\n","\n","        return (network_input, normalized_input)\n","\n","    def generate_notes(self, model, network_input, pitchnames, n_vocab):\n","        \"\"\" Generate notes from the neural network based on a sequence of notes \"\"\"\n","        int_to_note = dict((number + 1, note) for number, note in enumerate(pitchnames))\n","        int_to_note[0] = \"NULL\"\n","\n","        def get_start():\n","            # pick a random sequence from the input as a starting point for the prediction\n","            start = numpy.random.randint(0, len(network_input) - 1)\n","            pattern = network_input[start]\n","            prediction_output = []\n","            return pattern, prediction_output\n","\n","        # generate verse 1\n","        verse1_pattern, verse1_prediction_output = get_start()\n","        for note_index in range(4 * SEQUENCE_LEN):\n","            prediction_input = numpy.reshape(\n","                verse1_pattern, (1, len(verse1_pattern), 1)\n","            )\n","            prediction_input = prediction_input / float(n_vocab)\n","\n","            prediction = model.predict(prediction_input, verbose=0)\n","\n","            index = numpy.argmax(prediction)\n","            print(\"index\", index)\n","            result = int_to_note[index]\n","            verse1_prediction_output.append(result)\n","\n","            verse1_pattern.append(index)\n","            verse1_pattern = verse1_pattern[1 : len(verse1_pattern)]\n","\n","        # generate verse 2\n","        verse2_pattern = verse1_pattern\n","        verse2_prediction_output = []\n","        for note_index in range(4 * SEQUENCE_LEN):\n","            prediction_input = numpy.reshape(\n","                verse2_pattern, (1, len(verse2_pattern), 1)\n","            )\n","            prediction_input = prediction_input / float(n_vocab)\n","\n","            prediction = model.predict(prediction_input, verbose=0)\n","\n","            index = numpy.argmax(prediction)\n","            print(\"index\", index)\n","            result = int_to_note[index]\n","            verse2_prediction_output.append(result)\n","\n","            verse2_pattern.append(index)\n","            verse2_pattern = verse2_pattern[1 : len(verse2_pattern)]\n","\n","        # generate chorus\n","        chorus_pattern, chorus_prediction_output = get_start()\n","        for note_index in range(4 * SEQUENCE_LEN):\n","            prediction_input = numpy.reshape(\n","                chorus_pattern, (1, len(chorus_pattern), 1)\n","            )\n","            prediction_input = prediction_input / float(n_vocab)\n","\n","            prediction = model.predict(prediction_input, verbose=0)\n","\n","            index = numpy.argmax(prediction)\n","            print(\"index\", index)\n","            result = int_to_note[index]\n","            chorus_prediction_output.append(result)\n","\n","            chorus_pattern.append(index)\n","            chorus_pattern = chorus_pattern[1 : len(chorus_pattern)]\n","\n","        # generate bridge\n","        bridge_pattern, bridge_prediction_output = get_start()\n","        for note_index in range(4 * SEQUENCE_LEN):\n","            prediction_input = numpy.reshape(\n","                bridge_pattern, (1, len(bridge_pattern), 1)\n","            )\n","            prediction_input = prediction_input / float(n_vocab)\n","\n","            prediction = model.predict(prediction_input, verbose=0)\n","\n","            index = numpy.argmax(prediction)\n","            print(\"index\", index)\n","            result = int_to_note[index]\n","            bridge_prediction_output.append(result)\n","\n","            bridge_pattern.append(index)\n","            bridge_pattern = bridge_pattern[1 : len(bridge_pattern)]\n","\n","        return (\n","            verse1_prediction_output\n","            + chorus_prediction_output\n","            + verse2_prediction_output\n","            + chorus_prediction_output\n","            + bridge_prediction_output\n","            + chorus_prediction_output\n","        )\n","\n","    def create_midi(self, prediction_output):\n","        \"\"\" convert the output from the prediction to notes and create a midi file\n","            from the notes \"\"\"\n","        offset = 0\n","        output_notes = []\n","\n","        # create note and chord objects based on the values generated by the model\n","        for pattern in prediction_output:\n","            if \"$\" in pattern:\n","                pattern, dur = pattern.split(\"$\")\n","                if \"/\" in dur:\n","                    a, b = dur.split(\"/\")\n","                    dur = float(a) / float(b)\n","                else:\n","                    dur = float(dur)\n","\n","            # pattern is a chord\n","            if (\".\" in pattern) or pattern.isdigit():\n","                notes_in_chord = pattern.split(\".\")\n","                notes = []\n","                for current_note in notes_in_chord:\n","                    new_note = note.Note(int(current_note))\n","                    new_note.storedInstrument = instrument.Piano()\n","                    notes.append(new_note)\n","                new_chord = chord.Chord(notes)\n","                new_chord.offset = offset\n","                new_chord.duration = duration.Duration(dur)\n","                output_notes.append(new_chord)\n","            # pattern is a rest\n","            elif pattern is \"NULL\":\n","                offset += TIMESTEP\n","            # pattern is a note\n","            else:\n","                new_note = note.Note(pattern)\n","                new_note.offset = offset\n","                new_note.storedInstrument = instrument.Piano()\n","                new_note.duration = duration.Duration(dur)\n","                output_notes.append(new_note)\n","\n","            # increase offset each iteration so that notes do not stack\n","            offset += TIMESTEP\n","\n","        midi_stream = stream.Stream(output_notes)\n","\n","        output_file = self.weights + \".mid\"\n","        print(\"output to \" + output_file)\n","        midi_stream.write(\"midi\", fp=output_file)\n","\n","\n","main()\n"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","bidirectional_7 (Bidirection (None, 32, 1024)          2105344   \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 32, 1024)          0         \n","_________________________________________________________________\n","bidirectional_8 (Bidirection (None, 1024)              6295552   \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 1065)              1091625   \n","_________________________________________________________________\n","activation_4 (Activation)    (None, 1065)              0         \n","=================================================================\n","Total params: 9,492,521\n","Trainable params: 9,492,521\n","Non-trainable params: 0\n","_________________________________________________________________\n","index 0\n","index 94\n","index 0\n","index 28\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 5\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 28\n","index 0\n","index 15\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 128\n","index 0\n","index 151\n","index 0\n","index 283\n","index 0\n","index 360\n","index 0\n","index 232\n","index 0\n","index 0\n","index 0\n","index 100\n","index 0\n","index 670\n","index 0\n","index 935\n","index 0\n","index 836\n","index 0\n","index 746\n","index 0\n","index 670\n","index 0\n","index 479\n","index 0\n","index 670\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 935\n","index 0\n","index 836\n","index 0\n","index 746\n","index 0\n","index 795\n","index 0\n","index 840\n","index 0\n","index 836\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 836\n","index 0\n","index 670\n","index 0\n","index 746\n","index 0\n","index 670\n","index 0\n","index 836\n","index 0\n","index 670\n","index 0\n","index 746\n","index 0\n","index 476\n","index 0\n","index 670\n","index 0\n","index 1017\n","index 0\n","index 533\n","index 0\n","index 476\n","index 0\n","index 120\n","index 49\n","index 0\n","index 0\n","index 0\n","index 169\n","index 0\n","index 0\n","index 0\n","index 14\n","index 0\n","index 0\n","index 100\n","index 15\n","index 0\n","index 168\n","index 0\n","index 58\n","index 0\n","index 168\n","index 0\n","index 100\n","index 0\n","index 25\n","index 0\n","index 47\n","index 0\n","index 53\n","index 0\n","index 1033\n","index 0\n","index 695\n","index 836\n","index 0\n","index 0\n","index 0\n","index 935\n","index 0\n","index 1031\n","index 0\n","index 421\n","index 0\n","index 357\n","index 0\n","index 0\n","index 302\n","index 358\n","index 0\n","index 420\n","index 0\n","index 410\n","index 0\n","index 420\n","index 0\n","index 302\n","index 0\n","index 100\n","index 0\n","index 118\n","index 0\n","index 232\n","index 0\n","index 281\n","index 0\n","index 892\n","index 641\n","index 794\n","index 891\n","index 933\n","index 0\n","index 0\n","index 0\n","index 993\n","index 793\n","index 934\n","index 988\n","index 934\n","index 793\n","index 892\n","index 0\n","index 642\n","index 835\n","index 891\n","index 841\n","index 0\n","index 0\n","index 892\n","index 0\n","index 668\n","index 835\n","index 891\n","index 835\n","index 668\n","index 892\n","index 0\n","index 641\n","index 794\n","index 891\n","index 933\n","index 0\n","index 0\n","index 0\n","index 993\n","index 793\n","index 934\n","index 988\n","index 934\n","index 793\n","index 892\n","index 0\n","index 642\n","index 835\n","index 891\n","index 897\n","index 0\n","index 0\n","index 892\n","index 0\n","index 793\n","index 892\n","index 489\n","index 892\n","index 793\n","index 745\n","index 0\n","index 588\n","index 642\n","index 744\n","index 474\n","index 0\n","index 0\n","index 0\n","index 595\n","index 474\n","index 589\n","index 475\n","index 1016\n","index 474\n","index 745\n","index 0\n","index 589\n","index 642\n","index 744\n","index 841\n","index 0\n","index 0\n","index 835\n","index 0\n","index 588\n","index 203\n","index 61\n","index 203\n","index 61\n","index 203\n","index 61\n","index 0\n","index 262\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 856\n","index 0\n","index 769\n","index 0\n","index 691\n","index 0\n","index 1036\n","index 0\n","index 691\n","index 0\n","index 769\n","index 0\n","index 691\n","index 0\n","index 206\n","index 0\n","index 24\n","index 0\n","index 0\n","index 31\n","index 375\n","index 0\n","index 0\n","index 0\n","index 1040\n","index 0\n","index 0\n","index 0\n","index 685\n","index 684\n","index 0\n","index 0\n","index 436\n","index 856\n","index 0\n","index 769\n","index 0\n","index 691\n","index 0\n","index 1036\n","index 0\n","index 691\n","index 0\n","index 769\n","index 0\n","index 856\n","index 0\n","index 381\n","index 0\n","index 856\n","index 0\n","index 769\n","index 0\n","index 691\n","index 0\n","index 435\n","index 0\n","index 956\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 293\n","index 0\n","index 1052\n","index 0\n","index 1052\n","index 0\n","index 1052\n","index 0\n","index 352\n","index 0\n","index 691\n","index 0\n","index 691\n","index 0\n","index 769\n","index 0\n","index 5\n","index 0\n","index 379\n","index 0\n","index 0\n","index 383\n","index 49\n","index 0\n","index 0\n","index 0\n","index 490\n","index 605\n","index 684\n","index 207\n","index 608\n","index 687\n","index 766\n","index 763\n","index 255\n","index 849\n","index 0\n","index 0\n","index 1046\n","index 849\n","index 0\n","index 0\n","index 254\n","index 515\n","index 521\n","index 0\n","index 322\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 102\n","index 0\n","index 669\n","index 0\n","index 0\n","index 0\n","index 491\n","index 934\n","index 0\n","index 323\n","index 0\n","index 0\n","index 675\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 1042\n","index 1040\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 746\n","index 0\n","index 893\n","index 0\n","index 645\n","index 499\n","index 478\n","index 0\n","index 0\n","index 0\n","index 643\n","index 0\n","index 836\n","index 1033\n","index 0\n","index 478\n","index 746\n","index 0\n","index 945\n","index 836\n","index 0\n","index 478\n","index 670\n","index 0\n","index 941\n","index 177\n","index 0\n","index 672\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 757\n","index 0\n","index 935\n","index 557\n","index 0\n","index 746\n","index 0\n","index 428\n","index 0\n","index 491\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 941\n","index 359\n","index 0\n","index 104\n","index 0\n","index 0\n","index 0\n","index 697\n","index 0\n","index 0\n","index 0\n","index 836\n","index 676\n","index 0\n","index 836\n","index 0\n","index 935\n","index 1033\n","index 0\n","index 671\n","index 0\n","index 0\n","index 0\n","index 941\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 0\n","index 497\n","index 549\n","index 0\n","index 1040\n","index 548\n","index 0\n","index 0\n","index 0\n","index 772\n","index 696\n","index 0\n","index 0\n","index 0\n","index 836\n","index 670\n","output to /content/gdrive/My Drive/program/animLastChance/animLastChance-weights-improvement-04-0.0100-bigger.hdf5.mid\n"],"name":"stdout"}]}]}